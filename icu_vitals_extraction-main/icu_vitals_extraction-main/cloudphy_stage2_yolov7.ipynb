{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "#Install Dependencies\n",
        "\n",
        "_(Remember to choose GPU in Runtime if not already selected. Runtime --> Change Runtime Type --> Hardware accelerator --> GPU)_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGJspIl90XhV",
        "outputId": "5bf327c2-3dd3-4539-9ebc-ee851d8008ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Feb  5 05:31:42 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P0    26W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nD-uPyQ_2jiN",
        "outputId": "aa75e837-0d50-4cbf-b91c-3208936d7d74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'yolov7'...\n",
            "remote: Enumerating objects: 579, done.\u001b[K\n",
            "remote: Total 579 (delta 0), reused 0 (delta 0), pack-reused 579\u001b[K\n",
            "Receiving objects: 100% (579/579), 38.17 MiB | 38.17 MiB/s, done.\n",
            "Resolving deltas: 100% (287/287), done.\n",
            "/content/yolov7\n",
            "Branch 'fix/problems_associated_with_the_latest_versions_of_pytorch_and_numpy' set up to track remote branch 'fix/problems_associated_with_the_latest_versions_of_pytorch_and_numpy' from 'origin'.\n",
            "Switched to a new branch 'fix/problems_associated_with_the_latest_versions_of_pytorch_and_numpy'\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 4)) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 5)) (1.21.6)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 6)) (4.6.0.66)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 7)) (7.1.2)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 8)) (6.0)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 9)) (2.25.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 10)) (1.7.3)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 11)) (1.13.1+cu116)\n",
            "Requirement already satisfied: torchvision!=0.13.0,>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 12)) (0.14.1+cu116)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 13)) (4.64.1)\n",
            "Requirement already satisfied: protobuf<4.21.3 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 14)) (3.19.6)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 17)) (2.9.1)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 21)) (1.3.5)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 22)) (0.11.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 34)) (7.9.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 35)) (5.4.8)\n",
            "Collecting thop\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.4.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2.10)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (4.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.4.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.51.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (2.16.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.38.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.8.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.4.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.0.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 21)) (2022.7.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython->-r requirements.txt (line 34)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython->-r requirements.txt (line 34)) (0.7.5)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython->-r requirements.txt (line 34)) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipython->-r requirements.txt (line 34)) (5.7.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython->-r requirements.txt (line 34)) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython->-r requirements.txt (line 34)) (2.0.10)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython->-r requirements.txt (line 34)) (4.8.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (5.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.3.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython->-r requirements.txt (line 34)) (0.8.3)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 17)) (6.0.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->-r requirements.txt (line 34)) (0.2.6)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->ipython->-r requirements.txt (line 34)) (0.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.12.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.2.2)\n",
            "Installing collected packages: jedi, thop\n",
            "Successfully installed jedi-0.18.2 thop-0.1.1.post2209072238\n"
          ]
        }
      ],
      "source": [
        "# Download YOLOv7 repository and install requirements\n",
        "\n",
        "# !git clone https://github.com/WongKinYiu/yolov7\n",
        "# %cd yolov7\n",
        "# !pip install -r requirements.txt\n",
        "\n",
        "# current version of YOLOv7 is not compatible with pytorch>1.12.1 and numpy>1.20.1\n",
        "# until the appropriate changes get made to the main repository, we will be using a fork containing the patched code\n",
        "# you can track the progress here: https://github.com/roboflow/notebooks/issues/27\n",
        "!git clone https://github.com/SkalskiP/yolov7.git\n",
        "%cd yolov7\n",
        "!git checkout fix/problems_associated_with_the_latest_versions_of_pytorch_and_numpy\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtJ24mPlyF-S"
      },
      "source": [
        "# Download Correctly Formatted Custom Data\n",
        "\n",
        "Next, we'll download our dataset in the right format. Use the `YOLOv7 PyTorch` export. Note that this model requires YOLO TXT annotations, a custom YAML file, and organized directories. The roboflow export writes this for us and saves it in the correct spot.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHKrdSyFEMDp"
      },
      "outputs": [],
      "source": [
        "ROBOFLOW_KEY = \"BbhvgqhwoAejIuPghJ1M\" # CONFIDENTIAL: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovKgrVN8ygdW",
        "outputId": "9c6fd45c-4b72-424d-a164-5ad5e9887416"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: roboflow in /usr/local/lib/python3.8/dist-packages (0.2.29)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.8/dist-packages (from roboflow) (4.64.1)\n",
            "Requirement already satisfied: cycler==0.10.0 in /usr/local/lib/python3.8/dist-packages (from roboflow) (0.10.0)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.8/dist-packages (from roboflow) (0.10.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.8/dist-packages (from roboflow) (1.4.4)\n",
            "Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.8/dist-packages (from roboflow) (4.6.0.66)\n",
            "Requirement already satisfied: pyparsing==2.4.7 in /usr/local/lib/python3.8/dist-packages (from roboflow) (2.4.7)\n",
            "Requirement already satisfied: chardet==4.0.0 in /usr/local/lib/python3.8/dist-packages (from roboflow) (4.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from roboflow) (1.15.0)\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.8/dist-packages (from roboflow) (3.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from roboflow) (2.8.2)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.8/dist-packages (from roboflow) (1.26.14)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from roboflow) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.8/dist-packages (from roboflow) (1.21.6)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.8/dist-packages (from roboflow) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from roboflow) (2.25.1)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.8/dist-packages (from roboflow) (7.1.2)\n",
            "Requirement already satisfied: certifi==2022.12.7 in /usr/local/lib/python3.8/dist-packages (from roboflow) (2022.12.7)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.8/dist-packages (from roboflow) (0.21.1)\n",
            "Requirement already satisfied: idna==2.10 in /usr/local/lib/python3.8/dist-packages (from roboflow) (2.10)\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Exporting format yolov7pytorch in progress : 85.0%\n",
            "Version export complete for yolov7pytorch format\n",
            "Downloading Dataset Version Zip in cloudphy-ap-final-1 to yolov7pytorch: 100% [405535223 / 405535223] bytes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting Dataset Version Zip to cloudphy-ap-final-1 in yolov7pytorch:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4946/4946 [00:02<00:00, 1757.18it/s]\n"
          ]
        }
      ],
      "source": [
        "# REPLACE with your custom code snippet generated above\n",
        "\n",
        "!pip install roboflow\n",
        "\n",
        "# Dataset Download\n",
        "# TO GET DATASET DOWNLOAD VISIT https://app.roboflow.com/?model=YOLOS&ref=YOLOS\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=ROBOFLOW_KEY)\n",
        "# This project has all images of classification dataset provided by CloudPhy\n",
        "project = rf.workspace(\"aditya-prakash-3tcmk\").project(\"cloudphy-ap-final\")\n",
        "# The downloaded directory has all information on the augmentation and preprocessing regime in the accompanying txt file\n",
        "dataset = project.version(1).download(\"yolov7\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHfT9gEiBsBd"
      },
      "source": [
        "# Begin Custom Training\n",
        "\n",
        "We're ready to start custom training.\n",
        "\n",
        "NOTE: We will only modify one of the YOLOv7 training defaults in our example: `epochs`. We will adjust from 300 to 100 epochs in our example for speed. If you'd like to change other settings, see details in [our accompanying blog post](https://blog.roboflow.com/yolov7-custom-dataset-training-tutorial/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUbmy674bhpD",
        "outputId": "46fefdf1-44cf-4eae-c586-2eab3ea77ae1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/yolov7\n",
            "--2023-02-05 05:37:45--  https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7_training.pt\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/13e046d1-f7f0-43ab-910b-480613181b1f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230205%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230205T053746Z&X-Amz-Expires=300&X-Amz-Signature=f8d0ff0f43618738e60ad2dd849347f046b4f25369f9a7d03d08637f640c50f2&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7_training.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-02-05 05:37:46--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/13e046d1-f7f0-43ab-910b-480613181b1f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230205%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230205T053746Z&X-Amz-Expires=300&X-Amz-Signature=f8d0ff0f43618738e60ad2dd849347f046b4f25369f9a7d03d08637f640c50f2&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7_training.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 75628875 (72M) [application/octet-stream]\n",
            "Saving to: â€˜yolov7_training.ptâ€™\n",
            "\n",
            "yolov7_training.pt  100%[===================>]  72.12M   136MB/s    in 0.5s    \n",
            "\n",
            "2023-02-05 05:37:46 (136 MB/s) - â€˜yolov7_training.ptâ€™ saved [75628875/75628875]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# download COCO starting checkpoint\n",
        "%cd /content/yolov7\n",
        "!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7_training.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1iqOPKjr22mL",
        "outputId": "0288895c-a0b0-4b71-a942-1a56d8137d78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/yolov7\n",
            "YOLOR ðŸš€ b2a7de9 torch 1.13.1+cu116 CUDA:0 (Tesla T4, 15109.875MB)\n",
            "\n",
            "Namespace(adam=False, artifact_alias='latest', batch_size=2, bbox_interval=-1, bucket='', cache_images=False, cfg='', data='/content/yolov7/cloudphy-ap-final-1/data.yaml', device='0', entity=None, epochs=10, evolve=False, exist_ok=False, freeze=[0], global_rank=-1, hyp='data/hyp.scratch.p5.yaml', image_weights=False, img_size=[640, 640], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='exp', noautoanchor=False, nosave=False, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/exp', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=2, upload_dataset=False, v5_metric=False, weights='yolov7_training.pt', workers=8, world_size=1)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.0, paste_in=0.15, loss_ota=1\n",
            "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)\n",
            "Overriding model.yaml nc=80 with nc=7\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  5                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 10  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 11                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 12                -1  1         0  models.common.MP                        []                            \n",
            " 13                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 14                -3  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 16          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 18                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 20                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 23  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 24                -1  1    263168  models.common.Conv                      [512, 512, 1, 1]              \n",
            " 25                -1  1         0  models.common.MP                        []                            \n",
            " 26                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 27                -3  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 28                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 29          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 30                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 31                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 32                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 33                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 34                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 35                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 37                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
            " 38                -1  1         0  models.common.MP                        []                            \n",
            " 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 40                -3  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 42          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 43                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 44                -2  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 45                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 46                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 47                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 48                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 49  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 50                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
            " 51                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n",
            " 52                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 53                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 54                37  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 55          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 56                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 57                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 58                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 59                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 60                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 61                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 62[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 63                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 64                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 65                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 66                24  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 67          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 68                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 69                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 70                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n",
            " 71                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 72                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 73                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 74[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 75                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 76                -1  1         0  models.common.MP                        []                            \n",
            " 77                -1  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 78                -3  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 79                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 80      [-1, -3, 63]  1         0  models.common.Concat                    [1]                           \n",
            " 81                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 82                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 83                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 86                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 87[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 88                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 89                -1  1         0  models.common.MP                        []                            \n",
            " 90                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 91                -3  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 92                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 93      [-1, -3, 51]  1         0  models.common.Concat                    [1]                           \n",
            " 94                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 95                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 96                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n",
            " 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            "100[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            "101                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n",
            "102                75  1    328704  models.common.RepConv                   [128, 256, 3, 1]              \n",
            "103                88  1   1312768  models.common.RepConv                   [256, 512, 3, 1]              \n",
            "104               101  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]             \n",
            "105   [102, 103, 104]  1     66520  models.yolo.IDetect                     [7, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 415 layers, 37228920 parameters, 37228920 gradients, 105.2 GFLOPS\n",
            "\n",
            "Transferred 557/566 items from yolov7_training.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 95 .bias, 95 conv.weight, 98 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'cloudphy-ap-final-1/train/labels' images and labels... 2287 found, 0 missing, 0 empty, 0 corrupted: 100% 2287/2287 [00:00<00:00, 3628.17it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: cloudphy-ap-final-1/train/labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'cloudphy-ap-final-1/valid/labels' images and labels... 100 found, 0 missing, 0 empty, 0 corrupted: 100% 100/100 [00:00<00:00, 2674.72it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: cloudphy-ap-final-1/valid/labels.cache\n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 4.63, Best Possible Recall (BPR) = 0.9973\n",
            "Image sizes 640 train, 640 test\n",
            "Using 2 dataloader workers\n",
            "Logging results to runs/train/exp\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       0/9     2.47G   0.06853   0.02364   0.02864    0.1208         6       640: 100% 1144/1144 [04:56<00:00,  3.86it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 25/25 [00:05<00:00,  4.72it/s]\n",
            "                 all         100         619       0.322       0.278       0.163      0.0484\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       1/9     2.54G    0.0535   0.02087   0.02409   0.09847        20       640: 100% 1144/1144 [04:22<00:00,  4.36it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 25/25 [00:02<00:00, 12.17it/s]\n",
            "                 all         100         619       0.487       0.666       0.598       0.207\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       2/9     2.54G   0.04491   0.01936   0.01663    0.0809         9       640: 100% 1144/1144 [04:12<00:00,  4.53it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 25/25 [00:02<00:00,  9.06it/s]\n",
            "                 all         100         619       0.753        0.89        0.85       0.494\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       3/9     2.54G   0.03132   0.01712  0.008314   0.05676        12       640: 100% 1144/1144 [04:10<00:00,  4.57it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 25/25 [00:01<00:00, 12.60it/s]\n",
            "                 all         100         619       0.937       0.962       0.969       0.721\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       4/9     2.54G   0.02813   0.01511  0.004712   0.04795        17       640: 100% 1144/1144 [04:08<00:00,  4.59it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 25/25 [00:01<00:00, 12.92it/s]\n",
            "                 all         100         619       0.971       0.974       0.989       0.758\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       5/9     2.54G   0.02417   0.01367  0.003092   0.04093         2       640: 100% 1144/1144 [04:10<00:00,  4.57it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 25/25 [00:01<00:00, 12.55it/s]\n",
            "                 all         100         619       0.985       0.997        0.99       0.807\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       6/9     2.54G   0.02119   0.01266  0.002407   0.03625         6       640: 100% 1144/1144 [04:06<00:00,  4.63it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 25/25 [00:01<00:00, 12.68it/s]\n",
            "                 all         100         619       0.989       0.994        0.99       0.812\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       7/9     2.54G   0.01924   0.01262  0.002081   0.03394        10       640: 100% 1144/1144 [04:10<00:00,  4.57it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 25/25 [00:01<00:00, 12.59it/s]\n",
            "                 all         100         619       0.984       0.997        0.99       0.823\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       8/9     2.54G   0.01729   0.01207  0.001773   0.03114         9       640: 100% 1144/1144 [04:09<00:00,  4.58it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 25/25 [00:01<00:00, 12.78it/s]\n",
            "                 all         100         619       0.987       0.997        0.99       0.842\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       9/9     2.54G   0.01667   0.01152  0.001681   0.02987         4       640: 100% 1144/1144 [04:06<00:00,  4.64it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 25/25 [00:02<00:00,  8.34it/s]\n",
            "                 all         100         619       0.984       0.995        0.99       0.849\n",
            "                   0         100          99       0.986        0.99       0.981       0.884\n",
            "                   1         100          82       0.977           1       0.995       0.874\n",
            "                   2         100          82       0.993       0.988       0.995       0.862\n",
            "                   3         100          84       0.984           1       0.995       0.815\n",
            "                   4         100          85       0.984           1       0.986        0.89\n",
            "                   5         100          98       0.986           1       0.996       0.871\n",
            "                   6         100          89       0.978       0.989       0.982       0.748\n",
            "10 epochs completed in 0.726 hours.\n",
            "\n",
            "Optimizer stripped from runs/train/exp/weights/last.pt, 74.8MB\n",
            "Optimizer stripped from runs/train/exp/weights/best.pt, 74.8MB\n"
          ]
        }
      ],
      "source": [
        "# run this cell to begin training\n",
        "%cd /content/yolov7\n",
        "!python train.py --batch 2 --epochs 10 --data {dataset.location}/data.yaml --weights 'yolov7_training.pt' --device 0 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0W0MpUaTCJro"
      },
      "source": [
        "# Evaluation\n",
        "\n",
        "We can evaluate the performance of our custom training using the provided evalution script.\n",
        "\n",
        "Note we can adjust the below custom arguments. For details, see [the arguments accepted by detect.py](https://github.com/WongKinYiu/yolov7/blob/main/detect.py#L154)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4cfnLtTCIce",
        "outputId": "eb1fd86b-959e-4b7d-fd9d-dd2b7e41a5cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.1, device='', exist_ok=False, img_size=640, iou_thres=0.45, name='exp', no_trace=False, nosave=False, project='runs/detect', save_conf=False, save_txt=False, source='/content/81a8KdgRfnL.jpg', update=False, view_img=False, weights=['runs/train/exp/weights/best.pt'])\n",
            "YOLOR ðŸš€ b2a7de9 torch 1.13.1+cu116 CUDA:0 (Tesla T4, 15109.875MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36514136 parameters, 6194944 gradients, 103.3 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "4 0s, 3 1s, 4 2s, 4 4s, 2 5s, 1 6, Done. (19.1ms) Inference, (2.0ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp4/81a8KdgRfnL.jpg\n",
            "Done. (0.286s)\n"
          ]
        }
      ],
      "source": [
        "# Run evaluation\n",
        "!python detect.py --weights runs/train/exp/weights/best.pt --conf 0.1 --source /content/81a8KdgRfnL.jpg\n",
        "# {dataset.location}/test/images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6AGhNOSSHY4_"
      },
      "outputs": [],
      "source": [
        "# display inference on ALL test images\n",
        "\n",
        "import glob\n",
        "from IPython.display import Image, display\n",
        "\n",
        "i = 0\n",
        "limit = 10000 # max images to print\n",
        "for imageName in glob.glob('/content/yolov7/runs/detect/exp4/*.jpg'): #assuming JPG\n",
        "    if i < limit:\n",
        "      display(Image(filename=imageName))\n",
        "      print(\"\\n\")\n",
        "    i = i + 1\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMOfi7eLJCT3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMumI7a2JDAN"
      },
      "source": [
        "# Reparameterize for Inference\n",
        "\n",
        "https://github.com/WongKinYiu/yolov7/blob/main/tools/reparameterization.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcwRkxH4Kmj-"
      },
      "outputs": [],
      "source": [
        "# import\n",
        "from copy import deepcopy\n",
        "from models.yolo import Model\n",
        "import torch\n",
        "from utils.torch_utils import select_device, is_parallel\n",
        "import yaml\n",
        "\n",
        "device = select_device('0', batch_size=1)\n",
        "# model trained by cfg/training/*.yaml\n",
        "ckpt = torch.load('cfg/training/yolov7_training.pt', map_location=device)\n",
        "# reparameterized model in cfg/deploy/*.yaml\n",
        "model = Model('cfg/deploy/yolov7.yaml', ch=3, nc=80).to(device)\n",
        "\n",
        "with open('cfg/deploy/yolov7.yaml') as f:\n",
        "    yml = yaml.load(f, Loader=yaml.SafeLoader)\n",
        "anchors = len(yml['anchors'][0]) // 2\n",
        "\n",
        "# copy intersect weights\n",
        "state_dict = ckpt['model'].float().state_dict()\n",
        "exclude = []\n",
        "intersect_state_dict = {k: v for k, v in state_dict.items() if k in model.state_dict() and not any(x in k for x in exclude) and v.shape == model.state_dict()[k].shape}\n",
        "model.load_state_dict(intersect_state_dict, strict=False)\n",
        "model.names = ckpt['model'].names\n",
        "model.nc = ckpt['model'].nc\n",
        "\n",
        "# reparametrized YOLOR\n",
        "for i in range((model.nc+5)*anchors):\n",
        "    model.state_dict()['model.105.m.0.weight'].data[i, :, :, :] *= state_dict['model.105.im.0.implicit'].data[:, i, : :].squeeze()\n",
        "    model.state_dict()['model.105.m.1.weight'].data[i, :, :, :] *= state_dict['model.105.im.1.implicit'].data[:, i, : :].squeeze()\n",
        "    model.state_dict()['model.105.m.2.weight'].data[i, :, :, :] *= state_dict['model.105.im.2.implicit'].data[:, i, : :].squeeze()\n",
        "model.state_dict()['model.105.m.0.bias'].data += state_dict['model.105.m.0.weight'].mul(state_dict['model.105.ia.0.implicit']).sum(1).squeeze()\n",
        "model.state_dict()['model.105.m.1.bias'].data += state_dict['model.105.m.1.weight'].mul(state_dict['model.105.ia.1.implicit']).sum(1).squeeze()\n",
        "model.state_dict()['model.105.m.2.bias'].data += state_dict['model.105.m.2.weight'].mul(state_dict['model.105.ia.2.implicit']).sum(1).squeeze()\n",
        "model.state_dict()['model.105.m.0.bias'].data *= state_dict['model.105.im.0.implicit'].data.squeeze()\n",
        "model.state_dict()['model.105.m.1.bias'].data *= state_dict['model.105.im.1.implicit'].data.squeeze()\n",
        "model.state_dict()['model.105.m.2.bias'].data *= state_dict['model.105.im.2.implicit'].data.squeeze()\n",
        "\n",
        "# model to be saved\n",
        "ckpt = {'model': deepcopy(model.module if is_parallel(model) else model).half(),\n",
        "        'optimizer': None,\n",
        "        'training_results': None,\n",
        "        'epoch': -1}\n",
        "\n",
        "# save reparameterized model\n",
        "torch.save(ckpt, 'cfg/deploy/yolov7.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jn4kCtgKiGO"
      },
      "source": [
        "# OPTIONAL: Deployment\n",
        "\n",
        "To deploy, you'll need to export your weights and save them to use later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWOok8abrCsL",
        "outputId": "254dce78-e46e-4903-c2e9-078770163562"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: runs/detect/ (stored 0%)\n",
            "  adding: runs/detect/exp4/ (stored 0%)\n",
            "  adding: runs/detect/exp4/81a8KdgRfnL.jpg (deflated 3%)\n",
            "  adding: runs/detect/exp/ (stored 0%)\n",
            "  adding: runs/detect/exp/hcgnagpur_icu_mon-401_2022_10_23_13_30_1_jpeg.rf.c502875a3262f390a414bf593c1f0150.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/aveksha_micu_mon-121_2021_11_24_16_30_2_jpeg.rf.82549b0f0131cb38a22ececcaf47a014.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/aveksha_micu_mon-127_2021_11_23_12_0_27_jpeg.rf.381e32f51a40d7bf33c0415a9466a24a.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/charaklucknow_icu_mon-2_2022_10_22_21_15_29_jpeg.rf.947b416dc018e416e6376a9bd371adc2.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/prashant_icu_mon-16_2022_12_6_22_17_13_jpeg.rf.753722b8d2e6b5c3fd92b0ea0de19a7a.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/charaklucknow_icu_mon-2_2022_10_26_6_15_13_jpeg.rf.1f63e3b66243332ed0848e559ee664b2.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/siukaphahospital_icu_mon-5_2022_12_4_12_15_34_jpeg.rf.ad02e70be63ece33894cde94281ae6e8.jpg (deflated 6%)\n",
            "  adding: runs/detect/exp/charaklucknow_icu_mon-1_2022_11_2_16_15_4_jpeg.rf.a7dca32b198f44f7835ff4d4e49fa4fb.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/aveksha_micu_mon-125_2021_11_21_0_30_15_jpeg.rf.c50d935ab4f360dfdb3e7b097df07dad.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/charaklucknow_icu_mon-3_2022_10_23_10_15_44_jpeg.rf.fa528f63b5e26374f8abbe7c507c6d9a.jpg (deflated 6%)\n",
            "  adding: runs/detect/exp/hcgranchi_sicu_mon-326_2022_11_12_22_0_9_jpeg.rf.a8560428358dfc2875366790cda3a47b.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/hcgnagpur_icu_mon-1_2022_5_17_21_30_1_jpeg.rf.9ccbd2aa44facb0ab4433d49332bc0c3.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/hcgranchi_sicu_mon-326_2022_11_13_18_32_11_jpeg.rf.6b8065d2b0ea472c78da4188c01c1479.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/hcgnagpur_icu_mon-401_2022_10_25_0_30_1_jpeg.rf.5280a38ff35ec59b0a08e4ba5eff3c5e.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/prashant_icu_mon-16_2022_12_6_9_17_33_jpeg.rf.6ad4df7f02de92e7c364b16ca246678a.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/hcgnagpur_icu_mon-1_2022_5_12_12_30_3_jpeg.rf.0d95e7ccad193e8b586dca5dbec5a351.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/hcgranchi_sicu_mon-326_2022_11_23_2_31_0_jpeg.rf.75f9c51be57b8036b1e96f69d4465c08.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/hcgranchi_sicu_mon-326_2022_11_13_21_0_34_jpeg.rf.71e3f1e362132af01a14c3f4888d0a55.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/prashant_icu_mon-2_2022_11_26_8_15_20_jpeg.rf.2eeb425d074bbcb63a7fefaa6e54fc1f.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/prashant_icu_mon-16_2022_11_29_12_17_35_jpeg.rf.9ba8b2f9d8dbe89d9e65a5e83ac77537.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/hcgnagpur_icu_mon-1_2022_5_19_20_30_1_jpeg.rf.67041f22dd66348e419cad56915def3c.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/charaklucknow_icu_mon-6_2022_11_1_10_15_17_jpeg.rf.db30dce6839a78a53b2d16fc9ba4ef5a.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/aveksha_micu_mon-121_2021_11_26_13_30_2_jpeg.rf.f38f0b47dc0eca7d865c89bcb3f46a4d.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/hcgranchi_sicu_mon-326_2022_11_22_4_1_44_jpeg.rf.9881fcca7db0e823ae56fedabab2de2a.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/hcgranchi_sicu_mon-326_2022_11_18_22_30_6_jpeg.rf.c0d7824aad3fee5ce340b4161ad321cc.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/hcgnagpur_icu_mon-401_2022_10_31_15_30_1_jpeg.rf.29ef70f7f10784bdfafbf23ab5d6ca52.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/charaklucknow_icu_mon-3_2022_10_26_11_15_24_jpeg.rf.a5967f8b9738c1a36f4369b671ca0545.jpg (deflated 6%)\n",
            "  adding: runs/detect/exp/hcgranchi_sicu_mon-326_2022_11_11_1_30_43_jpeg.rf.1ed6b5b1463449a778fb120c3dad10d1.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/hcgranchi_sicu_mon-326_2022_11_22_15_30_49_jpeg.rf.2e7e087b1a994b20ee0eff19b9041919.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/hcgnagpur_icu_mon-402_2022_10_3_18_30_34_jpeg.rf.0d06ebf900300b03fea1bc1bb8ee501d.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/lifecarehospital_icu_mon-212_2022_9_9_6_0_12_jpeg.rf.4f3bc3d9c5f216a3b90a1ac54d4011fc.jpg (deflated 6%)\n",
            "  adding: runs/detect/exp/hcgranchi_sicu_mon-326_2022_11_15_5_0_21_jpeg.rf.cec1d9e7865cb1b33ea91e82061ec81e.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/lifecarehospital_icu_mon-216_2022_9_8_23_0_36_jpeg.rf.8c4e7d389cf04d826af3e2fe973832ee.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/prashant_icu_mon-1_2022_12_6_19_15_2_jpeg.rf.ffdc4a1380adc151df6efd4404defff6.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/lifecarehospital_icu_mon-216_2022_9_8_13_0_26_jpeg.rf.8f9bc4fb3725d327f231f95c3c4ea45d.jpg (deflated 6%)\n",
            "  adding: runs/detect/exp/hcgranchi_sicu_mon-326_2022_11_11_1_1_7_jpeg.rf.3dca00833181df33b00a1e8456840808.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/hcgnagpur_icu_mon-401_2022_10_24_20_30_1_jpeg.rf.ecee57afcd3ff67deaaa31aeabdf9f7c.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/prashant_icu_mon-1_2022_12_7_11_15_2_jpeg.rf.297bf6fd4109efeb71f5893329681f5d.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/hcgranchi_sicu_mon-326_2022_11_15_15_0_25_jpeg.rf.f3f631b798ecb441001dbf5dfcb49b0d.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/lifecarehospital_icu_mon-212_2022_9_10_1_0_12_jpeg.rf.851fd0a13b8406d0c12d2630427ed749.jpg (deflated 6%)\n",
            "  adding: runs/detect/exp/hcgranchi_sicu_mon-326_2022_11_22_7_0_44_jpeg.rf.01f349d90cc5c7b84a223cb08e125b30.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/hcgnagpur_icu_mon-401_2022_10_22_20_30_1_jpeg.rf.9f896fd931407b54c41cc04b7bec0d92.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/prashant_icu_mon-2_2022_11_26_10_15_24_jpeg.rf.527ac6e3149f4ed2d088c607ae02b761.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/charaklucknow_icu_mon-3_2022_10_24_5_15_16_jpeg.rf.e6134df19c1f4fe05897dbc8b5ba5b0b.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/prashant_icu_mon-1_2022_12_7_2_15_2_jpeg.rf.7ffb73eab6aa0d35a0418ccb964637b4.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/hcgnagpur_icu_mon-401_2022_10_19_22_30_1_jpeg.rf.7da923914ac88f1d283bad486d458ac2.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/lifecarehospital_icu_mon-214_2022_9_9_10_30_27_jpeg.rf.36c07b7a5fe6565fc7be97991a0055fc.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/prashant_icu_mon-16_2022_11_29_5_17_31_jpeg.rf.9e0b8fa0c48178c74be83fa594a335cb.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/prashant_icu_mon-16_2022_12_5_21_17_36_jpeg.rf.b66cde2850bed43cf799fd335edb0929.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/hcgnagpur_icu_mon-403_2022_10_13_15_30_27_jpeg.rf.2665cba58691c47e15a2005aa4e358e0.jpg (deflated 7%)\n",
            "  adding: runs/detect/exp/hcgranchi_sicu_mon-326_2022_11_10_21_30_34_jpeg.rf.abce4f77d13ade4d45ad4a6b6253b97f.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/hcgnagpur_icu_mon-403_2022_10_10_17_30_27_jpeg.rf.bd9329aa74a2610ae143ec6405b5d698.jpg (deflated 6%)\n",
            "  adding: runs/detect/exp/hcgnagpur_icu_mon-401_2022_10_3_17_30_5_jpeg.rf.ec1b71e5b12d1ee102ff88ad82626bee.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/hcgranchi_sicu_mon-326_2022_11_11_20_30_21_jpeg.rf.90104d4d90fdb9756315ff439ba4fe7b.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/hcgnagpur_icu_mon-401_2022_10_18_11_30_2_jpeg.rf.28e568122dab051871e3540163701f66.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/hcgranchi_sicu_mon-326_2022_11_15_18_30_40_jpeg.rf.cdd83de53a67a5ff3236c55bc9f861ac.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/siukaphahospital_icu_mon-5_2022_11_27_20_16_13_jpeg.rf.7ed362574fa0172e5b77dd9cc602f3f3.jpg (deflated 6%)\n",
            "  adding: runs/detect/exp/lifecarehospital_icu_mon-212_2022_9_10_9_30_15_jpeg.rf.8d9ecb15b5e29841716a4d0e3092c428.jpg (deflated 6%)\n",
            "  adding: runs/detect/exp/siukaphahospital_icu_mon-5_2022_12_3_16_15_52_jpeg.rf.f9b3a0a46476e2af80b8f61a529147c9.jpg (deflated 6%)\n",
            "  adding: runs/detect/exp/hcgranchi_sicu_mon-326_2022_11_15_4_30_23_jpeg.rf.0413b4cfd5ad17801c3474264e71b7c6.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/prashant_icu_mon-16_2022_12_1_20_16_17_jpeg.rf.f44e14214963c7d13dea324ed73c3896.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/hcgranchi_sicu_mon-326_2022_11_15_12_0_21_jpeg.rf.78c5e95e7a5e146dfe41e2687d56ded1.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/hcgranchi_sicu_mon-326_2022_11_19_1_30_59_jpeg.rf.828d8e5a26bd65618c695cc48cf96479.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/charaklucknow_icu_mon-6_2022_11_2_17_15_15_jpeg.rf.9e7b0a51cf42cb34ada8be32bc577294.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/hcgranchi_sicu_mon-326_2022_11_14_1_0_32_jpeg.rf.c36a05ed9910b1b26874556bab73161d.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/charaklucknow_icu_mon-1_2022_10_22_4_15_1_jpeg.rf.dfa35ba6bd59bf3ee4f2831da796cecf.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/prashant_icu_mon-1_2022_12_7_20_15_3_jpeg.rf.ee92e4c3dd99db9dcb3bd70ebe0b60a5.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/charaklucknow_icu_mon-2_2022_10_25_22_15_13_jpeg.rf.f9d80b1fc96d40ea5c1a473e7a2f5fc3.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/aveksha_micu_mon-127_2021_11_24_14_0_30_jpeg.rf.6280a8e2e55b76724de67e7ec5d32e59.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/hcgnagpur_icu_mon-402_2022_11_9_11_30_18_jpeg.rf.4c2e85b24e962549c2ffe7096b5799b3.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/hcgnagpur_icu_mon-401_2022_10_4_15_30_6_jpeg.rf.fe221e3b841c5d583bb4602fb6da7b53.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/aveksha_micu_mon-121_2021_11_24_20_0_3_jpeg.rf.cfeaa941ae5715de34562be957570b6e.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/charaklucknow_icu_mon-2_2022_10_22_1_15_29_jpeg.rf.71331295fa26864e5f5fb1d5a78772e1.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/hcgranchi_sicu_mon-326_2022_11_10_20_0_44_jpeg.rf.352ccefe91929fba6a401bce6c74b2be.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/hcgranchi_sicu_mon-326_2022_11_11_3_30_46_jpeg.rf.83db87835ef8e54b75f4c0707fb9849a.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/prashant_icu_mon-1_2022_12_6_23_15_2_jpeg.rf.44c565d542fdbac4b95ae77d4b655fb8.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp/lifecarehospital_icu_mon-212_2022_9_8_14_30_15_jpeg.rf.ab39dd3588636703588ebcd92dce58c3.jpg (deflated 6%)\n",
            "  adding: runs/detect/exp/hcgnagpur_icu_mon-1_2022_5_17_15_30_2_jpeg.rf.563e929b4c94d3f5912d23f5b3181eeb.jpg (deflated 7%)\n",
            "  adding: runs/detect/exp/siukaphahospital_icu_mon-5_2022_12_4_18_15_27_jpeg.rf.62c540233c5dace2a7c43de33f821c13.jpg (deflated 6%)\n",
            "  adding: runs/detect/exp/prashant_icu_mon-16_2022_12_4_9_17_9_jpeg.rf.8867bc2963aac2384b7048aa2f24a763.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp3/ (stored 0%)\n",
            "  adding: runs/detect/exp3/istockphoto-155421259-612x612.jpg (deflated 5%)\n",
            "  adding: runs/detect/exp2/ (stored 0%)\n",
            "  adding: runs/detect/exp2/aveksha_micu_mon-121_2021_11_23_13_30_2_jpeg.rf.4018212e3c65cdd307e181475c4b1137.jpg (deflated 5%)\n",
            "updating: runs/train/exp/weights/best.pt (deflated 8%)\n",
            "updating: runs/train/exp/confusion_matrix.png (deflated 29%)\n",
            "updating: runs/train/exp/events.out.tfevents.1675575498.39b58eaf15c8.2114.0 (deflated 58%)\n",
            "updating: runs/train/exp/F1_curve.png (deflated 10%)\n",
            "updating: runs/train/exp/hyp.yaml (deflated 44%)\n",
            "updating: runs/train/exp/opt.yaml (deflated 46%)\n",
            "updating: runs/train/exp/P_curve.png (deflated 18%)\n",
            "updating: runs/train/exp/PR_curve.png (deflated 21%)\n",
            "updating: runs/train/exp/R_curve.png (deflated 11%)\n",
            "updating: runs/train/exp/results.png (deflated 8%)\n",
            "updating: runs/train/exp/results.txt (deflated 71%)\n",
            "updating: runs/train/exp/test_batch0_labels.jpg (deflated 6%)\n",
            "updating: runs/train/exp/test_batch0_pred.jpg (deflated 6%)\n",
            "updating: runs/train/exp/test_batch1_labels.jpg (deflated 6%)\n",
            "updating: runs/train/exp/test_batch1_pred.jpg (deflated 5%)\n",
            "updating: runs/train/exp/test_batch2_labels.jpg (deflated 5%)\n",
            "updating: runs/train/exp/test_batch2_pred.jpg (deflated 5%)\n",
            "updating: runs/train/exp/train_batch0.jpg (deflated 14%)\n",
            "updating: runs/train/exp/train_batch1.jpg (deflated 17%)\n",
            "updating: runs/train/exp/train_batch2.jpg (deflated 11%)\n",
            "updating: runs/train/exp/train_batch3.jpg (deflated 8%)\n",
            "updating: runs/train/exp/train_batch4.jpg (deflated 10%)\n",
            "updating: runs/train/exp/train_batch5.jpg (deflated 8%)\n",
            "updating: runs/train/exp/train_batch6.jpg (deflated 14%)\n",
            "updating: runs/train/exp/train_batch7.jpg (deflated 12%)\n",
            "updating: runs/train/exp/train_batch8.jpg (deflated 8%)\n",
            "updating: runs/train/exp/train_batch9.jpg (deflated 10%)\n",
            "updating: runs/train/exp/weights/ (stored 0%)\n"
          ]
        }
      ],
      "source": [
        "# optional, zip to download weights and results locally\n",
        "\n",
        "!zip -r export.zip runs/detect\n",
        "!zip -r export.zip runs/train/exp/weights/best.pt\n",
        "!zip export.zip runs/train/exp/*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "!zip -r /content/yolov7/runs/train/exp/weights /content/yolov7/runs/train/exp/weights\n",
        "files.download('/content/yolov71_data.zip')"
      ],
      "metadata": {
        "id": "4y-mUIl-YZLN",
        "outputId": "4b586217-7c97-4880-b6b2-715342fcaa98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/yolov7/runs/train/exp/weights/ (stored 0%)\n",
            "  adding: content/yolov7/runs/train/exp/weights/epoch_000.pt (deflated 7%)\n",
            "  adding: content/yolov7/runs/train/exp/weights/best.pt (deflated 8%)\n",
            "  adding: content/yolov7/runs/train/exp/weights/last.pt (deflated 8%)\n",
            "  adding: content/yolov7/runs/train/exp/weights/epoch_009.pt (deflated 7%)\n",
            "  adding: content/yolov7/runs/train/exp/weights/epoch_007.pt (deflated 7%)\n",
            "  adding: content/yolov7/runs/train/exp/weights/epoch_008.pt (deflated 7%)\n",
            "  adding: content/yolov7/runs/train/exp/weights/init.pt (deflated 41%)\n",
            "  adding: content/yolov7/runs/train/exp/weights/epoch_006.pt (deflated 7%)\n",
            "  adding: content/yolov7/runs/train/exp/weights/epoch_005.pt (deflated 7%)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-2306e19e302a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'zip -r /content/yolov7/runs/train/exp/weights /content/yolov7/runs/train/exp/weights'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/yolov71_data.zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    207\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Cannot find file: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=undefined-variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m   \u001b[0mcomm_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_IPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomm_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Cannot find file: /content/yolov71_data.zip"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f41PvE5gKhYw"
      },
      "source": [
        "# OPTIONAL: Active Learning Example\n",
        "\n",
        "Once our first training run is complete, we should use our model to help identify which images are most problematic in order to investigate, annotate, and improve our dataset (and, therefore, model).\n",
        "\n",
        "To do that, we can execute code that automatically uploads images back to our hosted dataset if the image is a specific class or below a given confidence threshold.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcINqQS7Kt3-"
      },
      "outputs": [],
      "source": [
        "# # setup access to your workspace\n",
        "# rf = Roboflow(api_key=\"YOUR_API_KEY\")                               # used above to load data\n",
        "# inference_project =  rf.workspace().project(\"YOUR_PROJECT_NAME\")    # used above to load data\n",
        "# model = inference_project.version(1).model\n",
        "\n",
        "# upload_project = rf.workspace().project(\"YOUR_PROJECT_NAME\")\n",
        "\n",
        "# print(\"inference reference point: \", inference_project)\n",
        "# print(\"upload destination: \", upload_project)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEl1NVE3LSD_"
      },
      "outputs": [],
      "source": [
        "# # example upload: if prediction is below a given confidence threshold, upload it \n",
        "\n",
        "# confidence_interval = [10,70]                                   # [lower_bound_percent, upper_bound_percent]\n",
        "\n",
        "# for prediction in predictions:                                  # predictions list to loop through\n",
        "#   if(prediction['confidence'] * 100 >= confidence_interval[0] and \n",
        "#           prediction['confidence'] * 100 <= confidence_interval[1]):\n",
        "        \n",
        "#           # upload on success!\n",
        "#           print(' >> image uploaded!')\n",
        "#           upload_project.upload(image, num_retry_uploads=3)     # upload image in question"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}