# -*- coding: utf-8 -*-
"""Boundingbox.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yU-nb8nEVAxJUU87tF_vp9fK1jPrK9wD
"""

# import the necessary packages
import imutils
from skimage import exposure
import numpy as np
import argparse
import imutils
import cv2
from google.colab.patches import cv2_imshow
import numpy as np

# construct the argument parser and parse the arguments

# load the query image, compute the ratio of the old height
# to the new height, clone it, and resize it
image = cv2.imread("/content/spsludhiana_micuiithirdfloor_mon--MII07_2022_6_8_16_8_50.jpeg")
cv2_imshow(image)
ratio = image.shape[0] / 300.0
orig = image.copy()
image = imutils.resize(image, height = 300)
# convert the image to grayscale, blur it, and find edges
# in the image
gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
gray = cv2.bilateralFilter(gray, 11, 17, 17)
edged = cv2.Canny(gray, 30, 200)
cv2_imshow(edged)

from google.colab import drive
drive.mount('/content/drive')

# find contours in the edged image, keep only the largest
# ones, and initialize our screen contour
cnts = cv2.findContours(edged.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
cnts = imutils.grab_contours(cnts)
cnts = sorted(cnts, key = cv2.contourArea, reverse = True)[:10]
screenCnt = 0
print(cnts)

# loop over our contours
for c in cnts:
	# approximate the contour
	peri = cv2.arcLength(c, True)
	approx = cv2.approxPolyDP(c, 0.015 * peri, True)
	# if our approximated contour has four points, then
	# we can assume that we have found our screen
	if len(approx) == 4:
		screenCnt = approx
		break

cv2.drawContours(image, [screenCnt], -1, (0, 255, 0), 3) 
cv2_imshow(image) 
cv2.waitKey(0)

